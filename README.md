# Flux Learning - Provision Kubernetes Monitoring Stack

> **For learning purposes only. Should not be used in production.**

This repository contains [Flux](https://fluxcd.io) configuration to bootstrap a Kubernetes cluster with a basic monitoring and observability stack.

It provisions
- **Loki** for logs storage
- **Vector** to collect and send pod logs to Loki
- **Prometheus** with exporters to collect and store metrics
- **Grafana** for visualization

## Prerequisites

Flux cli is installed. https://fluxcd.io/flux/installation/

Access to a kubernetes cluster with a default storage class.

**Configuration has been tested with**

- [Kind](https://kind.sigs.k8s.io/docs/user/quick-start/)
- [Minikube](https://minikube.sigs.k8s.io/docs/start/?arch=%2Flinux%2Fx86-64%2Fstable%2Fbinary+download)
- [Rancher Desktop](https://rancherdesktop.io/)


<details>
<summary>For clusters without a default storage class:</summary>
<br>

1. Install local-path-provisioner by [Rancher](https://github.com/rancher/local-path-provisioner)


```bash
kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/master/deploy/local-path-storage.yaml
```

2. Add annotation to set it as default storageclass

```bash
kubectl patch storageclass local-path -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
```

</details>

<details>
<summary>For host machines with low number of file descriptors or inotify. (Too many open files related errors.)</summary>
<br>

1. Check your limits:

```bash
sudo sysctl fs.inotify.max_user_watches
sudo sysctl fs.inotify.max_user_instances
sudo ulimits -n
```

2. Increase limits (if needed):

```bash
sudo sysctl -w fs.inotify.max_user_watches=524288
sudo sysctl -w fs.inotify.max_user_instances=512
sudo ulimit -n 1048576
```
</details>


## How to bootstrap a cluster

**Generate a GitHub Personal Access Token**
  - Go to [https://github.com/settings/tokens](https://github.com/settings/tokens)
  - Select **repo** scope
  - Click Generate token at buttom of the page

**Configure token as an environment variable**

```bash
export GITHUB_TOKEN=your_token...
```

**Call flux to bootstrap the cluster**

```bash
flux bootstrap github \
    --token-auth  \
    --owner=arisfkiaras  \
    --repository=flux-learning  \
    --branch=main  \
    --path=clusters/my-cluster \
    --personal
```

**Wait for flux**
- If everything was installed correctly you should see 
```bash
✔ all components are healthy
```

- Execute ```kubectl get pods -A``` to see the status of individual pods. 

## How to access Grafana

**Forward the Grafana service to your local machine**

```bash
kubectl port-forward -n grafana service/grafana 8088:80
```

**Then open http://localhost:8088/dashboards in your browser.**

Grafana default credentials:
```
user: demo
pass: demo
```

You can browse the pre-installed dashboards or use the explore functionality of grafana, or create yoour own dashboards.

## Repository structure

```
├── apps                              # Contains the 'apps' installed on the cluster
│   ├── grafana
│   │   ├── kustomization.yaml
│   │   ├── namespace.yaml
│   │   └── release.yaml
│   ├── loki
│   │   ├── kustomization.yaml
│   │   ├── namespace.yaml
│   │   └── release.yaml
│   ├── prometheus
│   │   ├── kustomization.yaml
│   │   ├── namespace.yaml
│   │   └── release.yaml
│   └── vector
│       ├── config-map.yaml           # Contains sources/sink config for vector
│       ├── daemon-set.yaml
│       ├── kustomization.yaml
│       ├── namespace.yaml
│       └── rbac.yaml                 # RBAC required by Vector
├── clusters
│   └── my-cluster
│       ├── apps.yaml                 # Tells flux to keep track of ./app
│       ├── flux-system               # Auto-generated by flux
│       │   ├── gotk-components.yaml
│       │   ├── gotk-sync.yaml
│       │   └── kustomization.yaml
│       └── repositories.yaml         # Tells flux to keep track of ./repositories
├── README.md
└── repositories                      # Contains the helm repositories shared across apps.
    ├── grafana.yaml
    ├── kustomization.yaml
    └── prometheus-community.yaml
```

## Vector

To deploy Vector a custom DaemonSet was created [apps/vector/daemon-set.yaml](./apps/vector/daemon-set.yaml)

Sources and sinks are configured in a Config Map: [apps/vector/config-map.yaml](./apps/vector/config-map.yaml)

The configuration was inspired by [Vector Helm charts](https://github.com/vectordotdev/helm-charts/blob/develop/charts/vector)


### Useful links

- [Kubernetes Logs Source Documentation](https://vector.dev/docs/reference/configuration/sources/kubernetes_logs/)
- [Loki Sink Documentation](https://vector.dev/docs/reference/configuration/sinks/loki/)

## Loki

Loki is installed using the [Loki Helm chart](https://github.com/grafana/loki/blob/main/production/helm/loki) by Grafana. 

The Monolithic - Single Repilca setup was chosen.

[Minio](https://min.io/) is used as an S3-compatible object storage.

Helm Values can be configured in [apps/loki/release.yaml](./apps/loki/release.yaml)

### Useful Links

- [Loki Helm Installation Guide](https://grafana.com/docs/loki/latest/setup/install/helm/)
- [Loki Helm Chart Repository](https://github.com/grafana/loki/tree/main/production/helm/loki)
- [Loki Helm Chart Default Values](https://github.com/grafana/loki/blob/main/production/helm/loki/values.yaml)


## Prometheus

Prometheus is installed using the [prometheus-community](https://github.com/prometheus-community/helm-charts/tree/main/charts/prometheus) helm chart.

Helm values can be configured in [apps/prometheus/release.yaml](./apps/prometheus/release.yaml)

The installation includes:
- **prometheus server** to store the metrics and scrape the exporters
- **kube-state-metrics exporter** for kubernetes internal metrics like pod status.
- **node_exporter** for host machine metrics such as cpu usage.

### Useful Links

- [Prometheus Helm Chart](https://github.com/prometheus-community/helm-charts/tree/main/charts/prometheus/)
- [Prometheus Documentation](https://prometheus.io/docs/prometheus/latest/getting_started/)


## Grafana
Grafana is installed using the Grafana [Helm chart](https://github.com/grafana/helm-charts/blob/main/charts/grafana/README.md).

Helm values can be configured in [apps/grafana/release.yaml](./apps/grafana/release.yaml)

Loki and Prometheus datasources are automatically configured.

The following dashboards are also imported automatically from grafana.com:
- [Node Exporter Full](https://grafana.com/grafana/dashboards/1860-node-exporter-full/)
- [Logging Dashboard via Loki v2](https://grafana.com/grafana/dashboards/18042-logging-dashboard-via-loki-v2/)


#### Useful Links
- [Grafana.com Dashboards](https://grafana.com/grafana/dashboards/)
- [Helm Installation Documentation](https://grafana.com/docs/grafana/latest/setup-grafana/installation/helm/)


## Possible Improvements
- Create setup.sh script that will check if users has configured token, has access to cluster, ulimts, etc.
- Introduce multiple cluster setup, kustomize kubeadm clusters with auto-provision storage.
- Introduce an ingress for easier resources access.
- Add an nginx demo app and nginx collector/dashboard


<!-- 
- Add overview of what is deployed, some screenshots of grafana
- Add list of services including upstream documentation links, how to configure and how to access.
- Add how to fix too many open files issue if it comes up.
Nice to haves:
- Install ingress so its easier through one proxy to access all the apps.
- Add a few dashboards, provide better default grafana setup so user ends up directlyon dashboards.
- Add an nginx demo app and collect nginx metrics -->
